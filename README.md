# Deep Reinforcement Learning for Automated Testing  
**Assignment 1 â€“ CSCI 3060U / Topics in CS I**

This repository implements a modular **Deep Reinforcement Learning (DRL)** framework for **automated testing** of applications and games.  
Trained DRL agents (not scripted bots) explore environments, detect issues, and generate meaningful evaluation metrics using reproducible training setups.

---

## ğŸ¯ Project Overview

The goal is to **automate the testing of interactive systems** (2D/3D games, apps) using DRL agents trained with reward-driven personas.  
Agents are trained and evaluated across multiple environments using **PPO** and **A2C** algorithms.

---

## ğŸ§© Implemented Environments

| Environment | Description | Algorithms | Personas |
|--------------|-------------|-------------|-----------|
| **Snake** | Custom grid-based snake game | PPO, A2C | Survivor, Hunter|
| **MiniWorld â€“ Maze** | 3D maze navigation using MiniWorld | PPO, A2C | Explorer, Hunter|
| **CartPole** | Classic control benchmark for baseline testing | PPO, A2C | Solver, Fuzzer |
| **LunarLander** | Physics-based lander environment | PPO, DQN | Cautious,Aggressive |

> ğŸ§  Focus environments: **Snake** and **MiniWorld-Maze** (primary analysis)  
> Learning environments: **CartPole** and **LunarLander** (simpler baselines)

---

## ğŸ—ï¸ Folder Structure
```bash
SOKOBAN-ASSGN/
â”œâ”€â”€ envs/ # ğŸ§  Environment definitions & reward logic
â”‚ â”œâ”€â”€ cartpole/
â”‚ â”œâ”€â”€ lunarlander/
â”‚ â”œâ”€â”€ miniworld/
â”‚ â””â”€â”€ snake/
â”‚
â”œâ”€â”€ logs/ # ğŸ“Š Evaluation logs & TensorBoard runs
â”‚ â”œâ”€â”€ cartpole/
â”‚ â”œâ”€â”€ lunarlander/
â”‚ â”œâ”€â”€ miniworld/
â”‚ â””â”€â”€ snake/
â”‚
â”œâ”€â”€ media/ # ğŸ¥ Demo clips
|
â”œâ”€â”€ models/ # ğŸ’¾ Trained model checkpoints
â”‚ â”œâ”€â”€ cartpole/
â”‚ â”œâ”€â”€ lunarlander/
â”‚ â”œâ”€â”€ miniworld/
â”‚ â””â”€â”€ snake/
â”‚
â”œâ”€â”€ notebooks/ # ğŸ“’ Jupyter notebooks for analysis
â”‚ â”œâ”€â”€ miniworld_analysis.ipynb
â”‚ â””â”€â”€ snake_analysis.ipynb
â”‚
â”œâ”€â”€ plots/ # ğŸ“ˆ Generated plots and graphs
â”‚ â”œâ”€â”€ miniworld/
â”‚ â””â”€â”€ snake/
â”‚
â”œâ”€â”€ src/ # âš™ï¸ Source code (training, evaluation, visualization)
â”‚ â”œâ”€â”€ train_.py # Training scripts per environment
â”‚ â”œâ”€â”€ eval_.py # Evaluation & metric collection scripts (Generates CSV files)
â”‚ â”œâ”€â”€ visualize_*.py # Run live visualization or gameplay
â”‚ â”œâ”€â”€ README_cartpole.md
â”‚ â”œâ”€â”€ README_lunarlander.md
â”‚ â”œâ”€â”€ README_snake.md
â”‚ â””â”€â”€ README_miniworld.md
â”‚
â””â”€â”€ requirements.txt # ğŸ“¦ Dependency pinning for reproducibility
```


---

## âš™ï¸ Setup & Installation

```bash
# 1ï¸âƒ£ Create a virtual environment
python -m venv .venv
source .venv/bin/activate         # (Windows: .venv\Scripts\activate)

# 2ï¸âƒ£ Install dependencies
pip install -r requirements.txt
```